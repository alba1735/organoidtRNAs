{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "neural_color_dict = {'strong neural':'darkorange','neural':'gold','weak neural':'khaki','neutral':'darkgray','weak stem':'lightskyblue','stem':'deepskyblue','strong stem':'royalblue', 'undetermined':'mediumspringgreen'}\n",
    "seqtypes = ['arm.smallncRNAs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Build AnnData Objects\n",
    "\n",
    "The following code will build the AnnData objects from the tRAX run as described in the [README](README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqtype in seqtypes:\n",
    "    ! ../tRNAgraph/trnagraph.py build -i trax/{seqtype} -m config/metadata.tsv -o {seqtype}.h5ad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Manual addition of metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modification data is manually added to the AnnData objects for later analysis via clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqtype in seqtypes:\n",
    "    # Load the adata\n",
    "    adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "    # Load the mods table\n",
    "    mods_df = pd.read_csv('supplemental/ModTable_Human_labeled.txt', sep='\\t')\n",
    "    mods_df.rename(columns={'Unnamed: 0': 'trna'}, inplace=True)\n",
    "    # Add the mods to the adata.obs individually\n",
    "    for i in mods_df.columns[1:-1]:\n",
    "        mods_dict = dict(zip(mods_df['trna'], mods_df[i]))\n",
    "        adata.obs['mods_'+i] = adata.obs['trna'].map(mods_dict)\n",
    "\n",
    "    # Add fancy mod names for plotting as uns dict\n",
    "    mod_fancy_names_dict = {'m2G_6':r'm$^2$G 6', 'm2G_7':r'm$^2$G 7', 'm1A_9':r'm$^1$A 9', 'm1G_9':r'm$^1$G 9', 'm2G_10':r'm$^2$G 10', 'm1A_14':r'm$^1$A 14', 'acp3U_20':r'acp$^3$U 20', \\\n",
    "                        'm3C_20':r'm$^3$C 20', 'acp3U_20a':r'acp$^3$U 20a', 'm3C_20a':r'm$^3$C 20a', 'm22G_26':r'm$^2$$_2$G 26', 'm2G_26':r'm$^2$G 26', 'm22G_27':r'm$^2$$_2$G 27', \\\n",
    "                        'm3C_32':r'm$^3$C 32', 'I_34':r'I 34', 'm1A_37':r'm$^1$A 37', 'm1G_37':r'm$^1$G 37', 'm1I_37':r'm$^1$I 37', 'm6t6A_37':r'm$^6t^6$A 37', 'ms2t6A_37':r'ms$^2t^6$A 37', \\\n",
    "                        'm3C_e2':r'm$^3$C e2', 'm1A_58':r'm$^1$A 58'}\n",
    "    adata.uns['mod_fancy_names'] = mod_fancy_names_dict\n",
    "    \n",
    "    # Save the adata\n",
    "    adata.write_h5ad(f'{seqtype}.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add log2FC and p-value data to the AnnData objects for AlkBp filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqtype in seqtypes:\n",
    "    !../tRNAgraph/trnagraph.py tools log2fc -i {seqtype}.h5ad --cutoff 20 60 80 --config config/AlkBp.json --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the covariance, hmm, and secondary structure data from gtRNAdb and add it to the AnnData objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../rnadb/hg38-tRNAs-detailed.out', sep='\\t', header=2)\n",
    "# Keep columns 0, 1, 4, 5, 8, 9, 10\n",
    "df = df.iloc[:, [0, 1, 4, 5, 8, 9, 10]]\n",
    "df.columns = ['chr', 'trna', 'amino', 'iso', 'coveScore', 'HMM_score', 'SecStruct_score']\n",
    "# convert trna to gtRNAdb id\n",
    "name_df = pd.read_csv('../rnadb/hg38-tRNAs_name_map.txt', sep='\\t')\n",
    "name_dict = dict(zip(name_df['tRNAscan-SE_id'], name_df['GtRNAdb_id']))\n",
    "name_dict = {k:'-'.join(v.split('-')[:-1]) for k, v in name_dict.items()}\n",
    "df['trna'] = df['chr'] + '.trna' + df['trna'].astype(str)\n",
    "df['trna'] = df['trna'].map(name_dict)\n",
    "\n",
    "for seqtype in seqtypes:\n",
    "    adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "    # Add HMM score information\n",
    "    adata.obs['cove_score'] = adata.obs['trna'].map(dict(zip(df['trna'], df['coveScore'])))\n",
    "    adata.obs['hmm_score'] = adata.obs['trna'].map(dict(zip(df['trna'], df['HMM_score'])))\n",
    "    adata.obs['secstruct_score'] = adata.obs['trna'].map(dict(zip(df['trna'], df['SecStruct_score'])))\n",
    "    adata.write_h5ad(f'{seqtype}.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural and Stem cell markers are added to the AnnData object for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralStem():\n",
    "    def __init__(self, adata, compare, readtype, colselect):\n",
    "        self.adata = adata\n",
    "        self.colselect = colselect\n",
    "        self.percentiles = [0.1,0.2,0.3,0.5,0.7,0.8,0.9]\n",
    "        self.pvalcutoff = 0.05\n",
    "        # Search nested adata.uns for log2FC for compare and readtype\n",
    "        self.log2fc_dict = self.adata.uns.get('log2FC', {})\n",
    "        self.df = self.log2fc_dict['AlkBp'][compare][readtype]['20']['df']\n",
    "        self.pairs = self.log2fc_dict['AlkBp'][compare]['pairs']\n",
    "\n",
    "    def main(self):\n",
    "        self.qdf_pos, self.qdf_neg = self.gen_quartile_df()\n",
    "        self.assign_categories()\n",
    "        plt = self.plot_log2fc()\n",
    "        return self.adata, plt\n",
    "\n",
    "    def gen_quartile_df(self):\n",
    "        self.df = self.df[[f'log2_{self.colselect}',f'pval_{self.colselect}']]\n",
    "        self.df = self.df.sort_values(ascending=False, by=f'log2_{self.colselect}')\n",
    "        # self.df = self.df.to_frame()\n",
    "        self.df['trna'] = self.df.index.tolist()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        # Set column names\n",
    "        self.df.columns = ['log2FC','pval','trna']\n",
    "        # Scale the log2FC between -1 and 1\n",
    "        scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "        self.df['log2FC'] = scaler.fit_transform(self.df['log2FC'].values.reshape(-1,1))\n",
    "        # Split the df into positive and negative log2FC then calculate the quantile ranges for each before combining\n",
    "        pos_df = self.df[self.df['log2FC'] >= 0]\n",
    "        neg_df = self.df[self.df['log2FC'] <= 0]\n",
    "        pos_df = pos_df.describe(percentiles=self.percentiles[4:])\n",
    "        neg_df = neg_df.describe(percentiles=self.percentiles[:4])\n",
    "\n",
    "        return pos_df, neg_df\n",
    "\n",
    "    def assign_categories(self):\n",
    "        # Set category based on quantile ranges\n",
    "        neural_fine_dict, neural_broad_dict = {}, {}\n",
    "        for i,row in self.df.iterrows():\n",
    "            if row['log2FC'] > self.qdf_pos.loc[f'{int(self.percentiles[-1]*100)}%','log2FC'] and row['log2FC'] > self.qdf_pos.loc['50%','log2FC'] or row['log2FC'] >= 0.95:\n",
    "                if row['pval'] < self.pvalcutoff:\n",
    "                    neural_fine_dict[row['trna']] = 'strong neural'\n",
    "                    neural_broad_dict[row['trna']] = 'neural'\n",
    "                else:\n",
    "                    neural_fine_dict[row['trna']] = 'neutral'\n",
    "                    neural_broad_dict[row['trna']] = 'neutral'\n",
    "                continue\n",
    "            elif row['log2FC'] > self.qdf_pos.loc[f'{int(self.percentiles[-2]*100)}%','log2FC'] and row['log2FC'] > self.qdf_pos.loc['50%','log2FC'] or row['log2FC'] >= 0.90:\n",
    "                if row['pval'] < self.pvalcutoff:\n",
    "                    neural_fine_dict[row['trna']] = 'neural'\n",
    "                    neural_broad_dict[row['trna']] = 'neural'\n",
    "                else:\n",
    "                    neural_fine_dict[row['trna']] = 'neutral'\n",
    "                    neural_broad_dict[row['trna']] = 'neutral'\n",
    "                continue\n",
    "            elif row['log2FC'] > self.qdf_pos.loc[f'{int(self.percentiles[-3]*100)}%','log2FC'] and row['log2FC'] > self.qdf_pos.loc['50%','log2FC'] or row['log2FC'] >= 0.75:\n",
    "                if row['pval'] < self.pvalcutoff:\n",
    "                    neural_fine_dict[row['trna']] = 'weak neural'\n",
    "                    neural_broad_dict[row['trna']] = 'neural'\n",
    "                else:\n",
    "                    neural_fine_dict[row['trna']] = 'neutral'\n",
    "                    neural_broad_dict[row['trna']] = 'neutral'\n",
    "                continue\n",
    "            elif row['log2FC'] < self.qdf_neg.loc[f'{int(self.percentiles[0]*100)}%','log2FC'] and row['log2FC'] < self.qdf_neg.loc['50%','log2FC'] or row['log2FC'] <= -0.95:\n",
    "                if row['pval'] < self.pvalcutoff:\n",
    "                    neural_fine_dict[row['trna']] = 'strong stem'\n",
    "                    neural_broad_dict[row['trna']] = 'stem'\n",
    "                else:\n",
    "                    neural_fine_dict[row['trna']] = 'neutral'\n",
    "                    neural_broad_dict[row['trna']] = 'neutral'\n",
    "                continue\n",
    "            elif row['log2FC'] < self.qdf_neg.loc[f'{int(self.percentiles[1]*100)}%','log2FC'] and row['log2FC'] < self.qdf_neg.loc['50%','log2FC'] or row['log2FC'] <= -0.90:\n",
    "                if row['pval'] < self.pvalcutoff:\n",
    "                    neural_fine_dict[row['trna']] = 'stem'\n",
    "                    neural_broad_dict[row['trna']] = 'stem'\n",
    "                else:\n",
    "                    neural_fine_dict[row['trna']] = 'neutral'\n",
    "                    neural_broad_dict[row['trna']] = 'neutral'\n",
    "                continue\n",
    "            elif row['log2FC'] < self.qdf_neg.loc[f'{int(self.percentiles[2]*100)}%','log2FC'] and row['log2FC'] < self.qdf_neg.loc['50%','log2FC'] or row['log2FC'] <= -0.75:\n",
    "                if row['pval'] < self.pvalcutoff:\n",
    "                    neural_fine_dict[row['trna']] = 'weak stem'\n",
    "                    neural_broad_dict[row['trna']] = 'stem'\n",
    "                else:\n",
    "                    neural_fine_dict[row['trna']] = 'neutral'\n",
    "                    neural_broad_dict[row['trna']] = 'neutral'\n",
    "                continue\n",
    "            else:\n",
    "                neural_fine_dict[row['trna']] = 'neutral'\n",
    "                neural_broad_dict[row['trna']] = 'neutral'\n",
    "        self.df['neural_fine'] = self.df['trna'].map(neural_fine_dict)\n",
    "        self.df['neural_broad'] = self.df['trna'].map(neural_broad_dict)\n",
    "        self.adata.obs['neural_fine'] = self.adata.obs['trna'].map(neural_fine_dict)\n",
    "        self.adata.obs['neural_broad'] = self.adata.obs['trna'].map(neural_broad_dict)\n",
    "        # Replace NaN with neutral\n",
    "        self.adata.obs['neural_fine'] = self.adata.obs['neural_fine'].fillna('neutral') #.fillna('undetermined')\n",
    "        self.adata.obs['neural_broad'] = self.adata.obs['neural_broad'].fillna('neutral') #.fillna('undetermined')\n",
    "\n",
    "        log2fc_dict = dict(zip(self.df['trna'], self.df['log2FC']))\n",
    "        self.adata.obs['neural_stem_score'] = self.adata.obs['trna'].map(log2fc_dict)\n",
    "        # Fill NaN with 0\n",
    "        self.adata.obs['neural_stem_score'] = self.adata.obs['neural_stem_score'].fillna(0)\n",
    "\n",
    "    def plot_log2fc(self):\n",
    "        # Plot the slope\n",
    "        plt.figure(figsize=(6,18))\n",
    "        sns.barplot(x='log2FC', y='trna', data=self.df, hue='neural_fine', palette=neural_color_dict, dodge=False)\n",
    "        plt.xlabel('Slope')\n",
    "        plt.ylabel('tRNA')\n",
    "        plt.title('Slope of tRNA decay')\n",
    "        # Move the legend outside the plot\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., frameon=False)\n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "\n",
    "seqtype = 'arm.smallncRNAs'\n",
    "adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "adata, plt = neuralStem(adata, 'group', 'nreads_total_unique_norm', f'AlkBp_arm_d0-AlkBp_arm_d70').main()\n",
    "os.makedirs(f'figures/{seqtype}/neuralstem', exist_ok=True)\n",
    "plt.savefig(f'figures/{seqtype}/neuralstem/slope.pdf')\n",
    "# plt.close()\n",
    "adata.write_h5ad(f'{seqtype}.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clustering and HDBSCAN annotation\n",
    "\n",
    "The following code will run the cluster part of the pipeline on the ARMseq data with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomstate = 27\n",
    "readcutoff = 15\n",
    "\n",
    "coveragetype = ' '.join(['uniquecoverage', 'readstarts', 'readends', 'mismatchedbases', 'deletions'])\n",
    "\n",
    "sample_neighbors_cluster = 150\n",
    "sample_neighbors_plot = 75\n",
    "sample_hdbscan_min_samples = 6\n",
    "sample_hdbscan_min_cluster_size = 30\n",
    "sample_n_components = 10\n",
    "\n",
    "group_neighbors_cluster = 35\n",
    "group_neighbors_plot = 18\n",
    "group_hdbscan_min_samples = 4\n",
    "group_hdbscan_min_cluster_size = 12\n",
    "group_n_components = 10\n",
    "\n",
    "seqtype = 'arm.smallncRNAs'\n",
    "! ../tRNAgraph/trnagraph.py cluster -i {seqtype}.h5ad -o {seqtype}.h5ad \\\n",
    "    -r {randomstate} -t {readcutoff} -v {coveragetype} \\\n",
    "    -c1 {sample_n_components} -c2 {group_n_components} \\\n",
    "    -l1 {sample_neighbors_cluster} -l2 {group_neighbors_cluster} \\\n",
    "    -n1 {sample_neighbors_plot} -n2 {group_neighbors_plot} \\\n",
    "    -d1 {sample_hdbscan_min_samples} -d2 {group_hdbscan_min_samples} \\\n",
    "    -b1 {sample_hdbscan_min_cluster_size} -b2 {group_hdbscan_min_cluster_size} \\\n",
    "    --overwrite --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the percentage of stem/neural tRNAs in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad('arm.smallncRNAs.h5ad')\n",
    "adata = adata[~adata.obs['amino'].isin(['Und','Sup'])]\n",
    "# Add the neural_stem_score to the adata\n",
    "stem_neural_percent = {}\n",
    "for i in adata.obs['group_cluster'].dropna().unique():\n",
    "    tts = adata.obs[adata.obs['group_cluster'] == i][['nreads_total_unique_norm','neural_broad']].groupby('neural_broad', observed=True).describe()\n",
    "    tts['group_distribution'] = tts['nreads_total_unique_norm']['count'] / tts['nreads_total_unique_norm']['count'].sum()\n",
    "    tts['expression_distribution'] = tts['nreads_total_unique_norm']['mean'] / tts['nreads_total_unique_norm']['mean'].sum()\n",
    "    # Check if steam, neural and neutral rows exist and if not add them with 0\n",
    "    for j in ['stem','neural','neutral']:\n",
    "        if j not in tts.index:\n",
    "            tts.loc[j] = [0,0,0,0,0,0,0,0,0,0]\n",
    "    stem_neural_percent[i] = (tts['group_distribution']['neural'], tts['group_distribution']['stem'], tts['group_distribution']['neutral'], \\\n",
    "                              tts['expression_distribution']['neural'], tts['expression_distribution']['stem'], tts['expression_distribution']['neutral'])\n",
    "# Map this back to the adata\n",
    "adata.obs['group_cluster_neural_dist'] = adata.obs['group_cluster'].map({k:v[0] for k,v in stem_neural_percent.items()})\n",
    "adata.obs['group_cluster_stem_dist'] = adata.obs['group_cluster'].map({k:v[1] for k,v in stem_neural_percent.items()})\n",
    "adata.obs['group_cluster_neutral_dist'] = adata.obs['group_cluster'].map({k:v[2] for k,v in stem_neural_percent.items()})\n",
    "adata.obs['group_cluster_neural_expression'] = adata.obs['group_cluster'].map({k:v[3] for k,v in stem_neural_percent.items()})\n",
    "adata.obs['group_cluster_stem_expression'] = adata.obs['group_cluster'].map({k:v[4] for k,v in stem_neural_percent.items()})\n",
    "adata.obs['group_cluster_neutral_expression'] = adata.obs['group_cluster'].map({k:v[5] for k,v in stem_neural_percent.items()})\n",
    "adata.write_h5ad('arm.smallncRNAs.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign catgorical labels to each cluster based on the percentage of stem/neural tRNAs in each cluster as well as create a name dictionary for each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adata = ad.read_h5ad('arm.smallncRNAs.h5ad')\n",
    "df = adata.obs[['group_cluster','neural_stem_score','group_cluster_neural_dist','group_cluster_stem_dist','group_cluster_neutral_dist'\\\n",
    "                ,'group_cluster_neural_expression','group_cluster_stem_expression','group_cluster_neutral_expression']]\n",
    "# Drop nan and duplicates\n",
    "df = df.dropna()\n",
    "df.drop_duplicates(inplace=True)\n",
    "# grouby group_cluster and get the mean of neural_stem_score\n",
    "df = df.groupby('group_cluster').mean()\n",
    "# Scale the neural_stem_score between -1 and 1\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "df['neural_stem_score'] = scaler.fit_transform(df['neural_stem_score'].values.reshape(-1,1))\n",
    "# df['group_cluster_neural_percent'] = scaler.fit_transform(df['group_cluster_neural_percent'].values.reshape(-1,1))\n",
    "# Sort by neural_stem_score\n",
    "# df.sort_values(by='neural_stem_score', ascending=False, inplace=True)\n",
    "df['group_cluster_stem_expression'] = df['group_cluster_stem_expression'] * -1\n",
    "df.sort_values(by=['group_cluster_neural_expression','group_cluster_stem_expression'], ascending=False, inplace=True)\n",
    "# Create an alt_neural_stem_score by combining the neural and stem expression\n",
    "df['neural_stem_score_alt'] = df['group_cluster_neural_expression'] + df['group_cluster_stem_expression']\n",
    "# Scale the neural_stem_score between -1 and 1\n",
    "df['neural_stem_score_alt'] = scaler.fit_transform(df['neural_stem_score_alt'].values.reshape(-1,1))\n",
    "# Add to the adata\n",
    "neural_stem_score_alt_dict = dict(zip(df.index, df['neural_stem_score_alt']))\n",
    "adata.obs['neural_stem_score_alt'] = adata.obs['group_cluster'].map(neural_stem_score_alt_dict)\n",
    "df['group_cluster_stem_expression'] = df['group_cluster_stem_expression'] * -1\n",
    "# Determine if neural, stem, neutral based on the relative percentage\n",
    "cluster_names_dict = {17.:'B1',1.:'B2', 0.:'B3',15.:'B4',19.:'C14',16.:'C13',13.:'C12',14.:'C11',11.:'C10',8.:'C9',-1.:'U',2.:'C8',6.:'C7',10.:'C6',4.:'C5',18.:'C4',12.:'C3',9.:'C2',20.:'C1',7.:'A2',5.:'A3',3.:'A1'}\n",
    "adata.uns['cluster_names_dict'] = {str(k):v for k,v in cluster_names_dict.items()}\n",
    "# Create a dictionary to map the cluster to a number\n",
    "df['group_cluster_fancy'] = df.index.map(cluster_names_dict)\n",
    "adata.obs['group_cluster_fancy'] = adata.obs['group_cluster'].map(cluster_names_dict)\n",
    "# Also make a column that is the groups combined by A being Stem, B being Neural, C being Neutral, U being Undetermined, and NaN as Too Low\n",
    "cluster_dict = {'A':'Stem', 'B':'Neural', 'C':'Neutral', 'U':'Undetermined', np.nan:'Too Low', 'a':'Stem', 'b':'Neural'}\n",
    "for v in adata.obs['group_cluster_fancy'].unique():\n",
    "    # if v is dtype float then it is NaN\n",
    "    if type(v) == str:\n",
    "        cluster_dict[v] = cluster_dict[v[0]]\n",
    "# map the dict to the group_cluster_fancy column\n",
    "adata.obs['group_cluster_neural'] = adata.obs['group_cluster_fancy'].map(cluster_dict)\n",
    "# Create a dict for the group score\n",
    "group_score_dict = dict(zip(df.index, df['neural_stem_score']))\n",
    "adata.obs['group_cluster_score'] = adata.obs['group_cluster'].map(group_score_dict)\n",
    "# Save the adata\n",
    "adata.write_h5ad(f'arm.smallncRNAs.h5ad')\n",
    "# Print the df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterPlots9(adata, umapgroup, output):\n",
    "    # Define varibles\n",
    "    umap1 = '_'.join([umapgroup,'umap1'])\n",
    "    umap2 = '_'.join([umapgroup,'umap2'])\n",
    "    cluster = '_'.join([umapgroup,'cluster'])\n",
    "    point_size = 20\n",
    "    # Subset the AnnData object to the umapgroup where not NaN (i.e. clustered data that wasn't filtered out)\n",
    "    adata = adata[~adata.obs[cluster].isna(), :]\n",
    "    # Create a list of clusters greater than or equal to 0 in size to filter out non-clustered reads\n",
    "    hdbscan_annotated = adata.obs[cluster] >= 0\n",
    "    neural_annotated = adata.obs['neural_broad'] == 'neural'\n",
    "    stem_annotated = adata.obs['neural_broad'] == 'stem'\n",
    "    neutral_annotated = adata.obs['neural_broad'] == 'neutral'\n",
    "    # Create a 3 x 3 subplot with the umap projection and the cluster labels as the last subplot\n",
    "    fig, axs = plt.subplots(3, 3, figsize=(20,20))\n",
    "    # Plot first through ninth subplots\n",
    "    plot_list = [('Amino Acid','amino',0,0), ('Tissue Type','tissuetype',0,1), ('AlkB Treatment','treatment',0,2), \\\n",
    "                 ('Timepoint','timepoint',1,0), ('Fragment Type','fragment',1,1), ('Total Number of Reads Unique','nreads_total_unique_norm',1,2), \\\n",
    "                 ('Neural Fine','neural_fine',2,0), ('Neural Broad','neural_broad',2,1), ('HDBScan',cluster,2,2)]\n",
    "    for i in plot_list:\n",
    "        if i[2] == 1 and i[3] == 2:\n",
    "            pal = dict(zip(sorted(pd.unique(adata.obs[i[1]])), sns.color_palette(\"mako\", len(pd.unique(adata.obs[i[1]])))))\n",
    "        else:\n",
    "            if i[1] == cluster:\n",
    "                pal = dict(zip(sorted(pd.unique(adata.obs[i[1]][hdbscan_annotated])), sns.color_palette(\"hls\", len(pd.unique(adata.obs[i[1]]))-1)))\n",
    "            else:\n",
    "                pal = dict(zip(sorted(pd.unique(adata.obs[i[1]])), sns.color_palette(\"hls\", len(pd.unique(adata.obs[i[1]])))))\n",
    "        # Sort the adata object by the categorical variable for legend purposes\n",
    "        adata = adata[adata.obs[i[1]].sort_values().index, :]\n",
    "        if i[1] == cluster:\n",
    "            sns.scatterplot(x=adata.obs[umap1][~hdbscan_annotated], y=adata.obs[umap2][~hdbscan_annotated], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], color=np.array([(0.5,0.5,0.5)]), alpha=0.5, legend=False)\n",
    "            sns.scatterplot(x=adata.obs[umap1][hdbscan_annotated], y=adata.obs[umap2][hdbscan_annotated], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]][hdbscan_annotated], palette=pal, legend=False)\n",
    "            # Add labels to the plots\n",
    "            for j in adata.obs[cluster][hdbscan_annotated].unique():\n",
    "                x = adata.obs[umap1][adata.obs[cluster] == j].mean()\n",
    "                y = adata.obs[umap2][adata.obs[cluster] == j].mean()\n",
    "                # if umapgroup == 'group':\n",
    "                    # name = adata.obs['group_cluster_fancy'][adata.obs[cluster] == j].unique()[0]\n",
    "                # else:\n",
    "                name = adata.obs[cluster][adata.obs[cluster] == j].unique()[0]\n",
    "                axs[i[2],i[3]].text(x, y, name, fontsize=10, color='black', fontweight='bold')\n",
    "        elif i[1] == 'neural_broad' or i[1] == 'neural_fine':\n",
    "            sns.scatterplot(x=adata.obs[umap1][neutral_annotated], y=adata.obs[umap2][neutral_annotated], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]], palette=neural_color_dict, legend=False)\n",
    "            sns.scatterplot(x=adata.obs[umap1][stem_annotated], y=adata.obs[umap2][stem_annotated], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]], palette=neural_color_dict, legend=False)\n",
    "            sns.scatterplot(x=adata.obs[umap1][neural_annotated], y=adata.obs[umap2][neural_annotated], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]], palette=neural_color_dict, legend=False)\n",
    "        else:\n",
    "            sns.scatterplot(x=adata.obs[umap1], y=adata.obs[umap2], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]], palette=pal, legend=False)\n",
    "        axs[i[2],i[3]].set_title(i[0])\n",
    "        axs[i[2],i[3]].set_xlabel('UMAP 1')\n",
    "        axs[i[2],i[3]].set_ylabel('UMAP 2')\n",
    "        axs[i[2],i[3]].set_xticks([])\n",
    "        axs[i[2],i[3]].set_yticks([])\n",
    "        # Create legend from pal adding outside of plot and also reduce the size of the legend\n",
    "        # if i[2] != 1 and i[3] != 2:\n",
    "        #     axs[i[2],i[3]].legend(pd.unique(adata.obs[i[1]]), loc='upper right', bbox_to_anchor=(1.25, 1), frameon=False)\n",
    "    # Add title\n",
    "    fig.suptitle(f'UMAP Projection of tRNAs sorted by tRAX {umapgroup}', y=1.01)\n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output + f'/overview_9x_{umapgroup}.pdf')\n",
    "    # plt.close()\n",
    "\n",
    "def clusterPlots16(adata, umapgroup, output):\n",
    "    # Define varibles\n",
    "    umap1 = '_'.join([umapgroup,'umap1'])\n",
    "    umap2 = '_'.join([umapgroup,'umap2'])\n",
    "    cluster = '_'.join([umapgroup,'cluster'])\n",
    "    point_size = 20\n",
    "    # Subset the AnnData object to the umapgroup where not NaN (i.e. clustered data that wasn't filtered out)\n",
    "    adata = adata[~adata.obs[cluster].isna(), :]\n",
    "    # Create a list of clusters greater than or equal to 0 in size to filter out non-clustered reads\n",
    "    hdbscan_annotated = adata.obs[cluster] >= 0\n",
    "    # Create a 3 x 3 subplot with the umap projection and the cluster labels as the last subplot\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(24,24))\n",
    "    # Plot first through ninth subplots\n",
    "    plot_list = [('Amino Acid','amino',0,0), ('HDBScan',cluster,0,1), ('mods_6','mods_6',0,2), ('mods_7','mods_7',0,3), \\\n",
    "                 ('mods_9','mods_9',1,0), ('mods_10','mods_10',1,1), ('mods_14','mods_14',1,2), ('mods_20','mods_20',1,3), \\\n",
    "                 ('mods_20a','mods_20a',2,0), ('mods_26','mods_26',2,1), ('mods_27','mods_27',2,2), ('mods_32','mods_32',2,3), \\\n",
    "                 ('mods_34','mods_34',3,0), ('mods_37','mods_37',3,1), ('mods_e2','mods_e2',3,2), ('mods_58','mods_58',3,3)]\n",
    "\n",
    "    for i in plot_list:\n",
    "        # Determine wether to mask NaN values\n",
    "        masking = False\n",
    "        if adata.obs[i[1]].isna().any() or i[1] == cluster:\n",
    "            masking = True\n",
    "            if i[1] == cluster:\n",
    "                # Create a list of clusters greater than or equal to 0 in size to filter out non-clustered reads from the HDBScan cluster\n",
    "                mask = adata.obs[cluster] >= 0\n",
    "            else:\n",
    "                mask = ~adata.obs[i[1]].isnull()\n",
    "        # Create a palette for the categorical variable\n",
    "        if i[1] == cluster:\n",
    "            pal = dict(zip(sorted(pd.unique(adata.obs[i[1]][hdbscan_annotated])), sns.color_palette(\"hls\", len(pd.unique(adata.obs[i[1]]))-1)))\n",
    "        else:\n",
    "            if masking:\n",
    "                pal = dict(zip(sorted(pd.unique(adata.obs[i[1]][mask])), sns.color_palette(\"hls\", len(pd.unique(adata.obs[i[1]][mask])))))\n",
    "            else:\n",
    "                pal = dict(zip(sorted(pd.unique(adata.obs[i[1]])), sns.color_palette(\"hls\", len(pd.unique(adata.obs[i[1]])))))\n",
    "        # Sort the adata object by the categorical variable for legend purposes\n",
    "        adata = adata[adata.obs[i[1]].sort_values().index, :]\n",
    "        if masking:\n",
    "            sns.scatterplot(x=adata.obs[umap1][~mask], y=adata.obs[umap2][~mask], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], color=np.array([(0.5,0.5,0.5)]), alpha=0.5, legend=False)\n",
    "            sns.scatterplot(x=adata.obs[umap1][mask], y=adata.obs[umap2][mask], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]][mask], palette=pal, legend=False)\n",
    "            if i[1] == cluster:\n",
    "                # Add labels to the plots\n",
    "                for j in adata.obs[cluster][hdbscan_annotated].unique():\n",
    "                    x = adata.obs[umap1][adata.obs[cluster] == j].mean()\n",
    "                    y = adata.obs[umap2][adata.obs[cluster] == j].mean()\n",
    "                    if umapgroup == 'group':\n",
    "                        name = adata.obs['group_cluster_fancy'][adata.obs[cluster] == j].unique()[0]\n",
    "                    else:\n",
    "                        name = adata.obs[cluster][adata.obs[cluster] == j].unique()[0]\n",
    "                    axs[i[2],i[3]].text(x, y, name, fontsize=10, color='black', fontweight='bold')\n",
    "        else:\n",
    "            sns.scatterplot(x=adata.obs[umap1], y=adata.obs[umap2], s=point_size, linewidth=0.25, ax=axs[i[2],i[3]], hue=adata.obs[i[1]], palette=pal, legend=False)\n",
    "        axs[i[2],i[3]].set_title(i[0])\n",
    "        axs[i[2],i[3]].set_xlabel('UMAP 1')\n",
    "        axs[i[2],i[3]].set_ylabel('UMAP 2')\n",
    "        axs[i[2],i[3]].set_xticks([])\n",
    "        axs[i[2],i[3]].set_yticks([])\n",
    "        # Create legend from pal adding outside of plot and also reduce the size of the legend\n",
    "        # if i[2] != 1 and i[3] != 2:\n",
    "        #     axs[i[2],i[3]].legend(pd.unique(adata.obs[i[1]]), loc='upper right', bbox_to_anchor=(1.25, 1), frameon=False)\n",
    "    # Add title\n",
    "    fig.suptitle(f'UMAP Projection of tRNAs sorted by tRAX {umapgroup}', y=1.01)\n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output + f'/overview_mods_{umapgroup}.pdf')\n",
    "    # plt.close()\n",
    "\n",
    "adata = ad.read_h5ad('arm.smallncRNAs.h5ad')\n",
    "os.makedirs('figures/arm.smallncRNAs/cluster/', exist_ok=True)\n",
    "output = 'figures/arm.smallncRNAs/cluster'\n",
    "# Plot the UMAP projection\n",
    "# clusterPlots9(adata.copy(), 'sample', output)\n",
    "clusterPlots9(adata.copy(), 'group', output)\n",
    "# clusterPlots16(adata.copy(), 'sample', output)\n",
    "clusterPlots16(adata.copy(), 'group', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "# Generate the cluster overview plots\n",
    "print('Generating cluster overview plots...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clusteroverview -o figures/{seqtype}/ \n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clustergrp group_cluster --clusterlabel group_cluster_fancy -o figures/{seqtype}/ --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "# Generate the cluster plots for discrete groups\n",
    "plot_list = [('Amino Type','amino'), ('Tissue Type','tissuetype'), ('AlkB Treatment','treatment'), ('Timepoint','timepoint'), \\\n",
    "             ('Fragment Type','fragment'), ('Neural Fine','neural_fine'), ('Neural Broad','neural_broad')]\n",
    "print('Generating cluster plots for discrete groups...')\n",
    "for i in plot_list:\n",
    "    print(i[0])\n",
    "    ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clustergrp {i[1]} --clustermask -o figures/{seqtype}/ --quiet\n",
    "    ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clustergrp {i[1]} -o figures/{seqtype}/ --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "# # Generate the cluster plots for continuous groups\n",
    "# plot_list = [('hmm_score','hmm_score'), ('secstruct_score','secstruct_score'), ('cove_score','cove_score')]\n",
    "plot_list = [('neural_stem_score','neural_stem_score')]\n",
    "# print('Generating cluster plots for continuous groups...')\n",
    "for i in plot_list:\n",
    "    ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clustergrp {i[1]} --clusternumeric -o figures/{seqtype}/ #--quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "# Generate the cluster plots for the neural_stem_score with HDBScan cluster labels\n",
    "print('Generating cluster plots for the neural_stem_score...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clustergrp group_cluster_neural --clusterlabel group_cluster_fancy --clustermask -o figures/{seqtype}/\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g cluster --clustergrp group_cluster_fancy --clusterlabel group_cluster_fancy --clustermask -o figures/{seqtype}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Custom visualizations\n",
    "\n",
    "Plots to support conclusions in the paper, such as dot matrix plots, and kmer heatmaps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modification Correlation Plot\n",
    "\n",
    "The mod correlation plot is a dotplot of the correlation between the modification levels, the average neural-stem stem log2FC score, and the HDBSCAN group clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "cluster_names_dict = {float(k):v for k,v in adata.uns['cluster_names_dict'].items()}\n",
    "# Create a df of the mods\n",
    "mods_df = pd.DataFrame(adata.obs[['mods_6','mods_7','mods_9','mods_10','mods_14','mods_20','mods_20a','mods_26','mods_27','mods_32','mods_34','mods_37','mods_e2','mods_58']])\n",
    "for mod in mods_df.columns:\n",
    "    # Get unique mods for each mod\n",
    "    mods = mods_df[mod].dropna().unique()\n",
    "    for i in mods:\n",
    "        mods_df[i+'_'+mod.split('_')[1]] = mods_df[mod].str.contains(i)\n",
    "    # Drop the original mod column\n",
    "    mods_df.drop(mod, axis=1, inplace=True)\n",
    "# Add the group_cluster column from the adata.obs and the trna column from the adata.obs\n",
    "mods_df['group_cluster'] = adata.obs['group_cluster']\n",
    "# Convert all False to NaN\n",
    "mods_df.replace(False, np.nan, inplace=True)\n",
    "# Drop the NaN values from the mods\n",
    "mods_df = mods_df[~mods_df['group_cluster'].isna()]\n",
    "# Count the number of unique mods in each cluster\n",
    "mods_df = mods_df.groupby(['group_cluster']).agg(['value_counts']).T\n",
    "# Drop the the multiindex\n",
    "mods_df = mods_df.droplevel(1)\n",
    "mods_df = mods_df.T.droplevel(1)\n",
    "# Convert group_cluster to int\n",
    "mods_df.index.name = None\n",
    "mods_df.index = mods_df.index.astype(int)\n",
    "# Sort the columns by the index\n",
    "mods_df = mods_df.sort_index(axis=0)\n",
    "mods_df = mods_df.sort_index(axis=1)\n",
    "# Replace NaN with 0\n",
    "mods_df.fillna(0, inplace=True)\n",
    "\n",
    "# Make a df of value counts for each group_cluster\n",
    "group_cluster_df = pd.DataFrame(adata.obs['group_cluster'].value_counts())\n",
    "# group_cluster_df = group_cluster_df.reset_index()\n",
    "group_cluster_df.index = group_cluster_df.index.astype(int)\n",
    "# Sort the df by the index\n",
    "group_cluster_df = group_cluster_df.sort_values(by='group_cluster')\n",
    "# Drop the index name\n",
    "group_cluster_df.index.name = None\n",
    "# combine the mods_df and group_cluster_df on the index\n",
    "mods_df = mods_df.join(group_cluster_df)\n",
    "# divide each column by the count of the group_cluster\n",
    "for i in mods_df.columns[:-1]:\n",
    "    mods_df[i] = mods_df[i]/mods_df['count']\n",
    "# Drop the count column\n",
    "mods_df.drop('count', axis=1, inplace=True)\n",
    "\n",
    "# Melting the dataframe for corr plotting\n",
    "corr_df = mods_df.copy()\n",
    "corr_df['cluster'] = corr_df.index\n",
    "corr_df = corr_df.melt(id_vars=['cluster'], var_name='mods', value_name='Modification Proportion')\n",
    "# Sort the mods column by the number\n",
    "corr_df['sortmods'] = corr_df['mods'].str.split('_').str[1]\n",
    "# Convert the 20a to 20\n",
    "corr_df['sortmods'] = corr_df['sortmods'].replace('20a','20.1')\n",
    "# Convert e2 to 46\n",
    "corr_df['sortmods'] = corr_df['sortmods'].replace('e2','46')\n",
    "# Convert the sortmods to int\n",
    "corr_df['sortmods'] = corr_df['sortmods'].astype(float)\n",
    "corr_df = corr_df.sort_values(by=['cluster','sortmods','mods'])\n",
    "neural_stem_score_dict = {}\n",
    "for cluster in adata.obs['group_cluster'].unique():\n",
    "    neural_stem_score_dict[cluster] = adata.obs[adata.obs['group_cluster'] == cluster]['neural_stem_score'].dropna().drop_duplicates().mean() #['group_cluster_neural_percent'].mean() \n",
    "corr_df['Neural Stem Score'] = corr_df['cluster'].map(neural_stem_score_dict)\n",
    "# Since the mean of the neural_stem_score was taken, it needs to be scaled between 0 and 1 again\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "corr_df['Neural Stem Score'] = scaler.fit_transform(corr_df['Neural Stem Score'].values.reshape(-1,1))\n",
    "# Since relplot always sorts the x-axis this needs to be done to sort the mods by the mean of the Neural Stem Score\n",
    "# Sort df by mean score of Neural Stem Score\n",
    "corr_df = corr_df.sort_values(by=['Neural Stem Score','sortmods','mods'])\n",
    "corr_df = corr_df.reset_index(drop=True)\n",
    "cluster_sort_list = corr_df['cluster'].unique()\n",
    "# Create a dictionary to map the cluster to a number\n",
    "cluster_dict = dict(zip(cluster_sort_list, range(0,len(cluster_sort_list))))\n",
    "# Map the dictionary to the cluster column\n",
    "corr_df['cluster'] = corr_df['cluster'].map(cluster_dict)\n",
    "# Create a dictionary to map the number back to the cluster\n",
    "cluster_dict_rev = dict(zip(range(0,len(cluster_sort_list)), cluster_sort_list))\n",
    "\n",
    "# Map the mods to the fancy names\n",
    "corr_df['mods'] = corr_df['mods'].map(adata.uns['mod_fancy_names'])\n",
    "# Create a diverging color palette with 64 as the separation point value meaning 1/4 of the palette is used for each side\n",
    "# cmap = sns.diverging_palette(255, 85, s=255, l=70, sep=32, as_cmap=True)\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('blend', ['deepskyblue','silver','gold'])\n",
    "# Plot the correlation\n",
    "axs = sns.relplot(x='cluster', y='mods', hue='Neural Stem Score', size='Modification Proportion', data=corr_df, palette=cmap, edgecolor=\".7\", \n",
    "                  height=10, sizes=(0, 225), size_norm=(-.01, 1))\n",
    "# Add a vertical lines to separate the clusters at the 1/4 and 3/4 range\n",
    "axs.ax.axvline(2.5, color='black', linestyle='--')\n",
    "axs.ax.axvline(17.5, color='black', linestyle='--')\n",
    "# axs.map(plt.axvline, x=2.5, color='black', linestyle='--')\n",
    "# axs.map(plt.axvline, x=17.5, color='black', linestyle='--')\n",
    "# Add lines at 25% and 75% percentile\n",
    "# axs.map(plt.axvline, x=corr_df[['cluster','Neural Stem Score']].describe(percentiles=[0.25]).loc[['25%']]['cluster'].values+0.5, color='black', linestyle='--')\n",
    "# axs.map(plt.axvline, x=corr_df[['cluster','Neural Stem Score']].describe(percentiles=[0.75]).loc[['75%']]['cluster'].values-0.5, color='black', linestyle='--')\n",
    "# Add labels to the points\n",
    "axs.set(ylabel=\"Modification by Position\", xlabel=\"Cluster Groups\", aspect=\"equal\")\n",
    "axs.despine(left=True, bottom=True)\n",
    "# Use cluster_names_dict to map the cluster number to the cluster name from earlier in the notebook\n",
    "axs.set(xticks=np.arange(len(mods_df.index)), xticklabels=[cluster_names_dict[cluster_dict_rev[i]] for i in np.arange(0,len(mods_df.index))])\n",
    "# Set title\n",
    "plt.title('tRNA modification Prevalence by Cluster')\n",
    "# Move legend outside of plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., frameon=False)\n",
    "axs._legend.remove()\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/{seqtype}/cluster/mods_corr.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amino Correlation Plot\n",
    "\n",
    "The amino correlation plot is a dotplot of the correlation between the isotype proportion, the average neural-stem stem log2FC score, and the HDBSCAN group clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "# Create a df of the aminos\n",
    "aminos_df = pd.DataFrame(adata.obs['amino'])\n",
    "\n",
    "for amino in aminos_df.columns:\n",
    "    # Get unique amino acids for each column \n",
    "    aminos = aminos_df[amino].dropna().unique()\n",
    "    for i in aminos:\n",
    "        aminos_df[i] = aminos_df[amino].str.contains(i)\n",
    "    # Drop the original mod column\n",
    "    aminos_df.drop(amino, axis=1, inplace=True)\n",
    "# Add the group_cluster column from the adata.obs and the trna column from the adata.obs\n",
    "aminos_df['group_cluster'] = adata.obs['group_cluster']\n",
    "# Drop Und and Sup from the aminos_df\n",
    "# aminos_df.drop(['Und','Sup'], axis=1, inplace=True)\n",
    "# Convert all False to NaN\n",
    "aminos_df.replace(False, np.nan, inplace=True)\n",
    "# Drop the NaN values from the aminos\n",
    "aminos_df = aminos_df[~aminos_df['group_cluster'].isna()]\n",
    "# Count the number of unique aminos in each cluster\n",
    "aminos_df = aminos_df.groupby(['group_cluster']).agg(['value_counts']).T\n",
    "# Drop the the multiindex\n",
    "aminos_df = aminos_df.droplevel(1)\n",
    "aminos_df = aminos_df.T.droplevel(1)\n",
    "# Convert group_cluster to int\n",
    "aminos_df.index.name = None\n",
    "aminos_df.index = aminos_df.index.astype(int)\n",
    "# Sort the columns by the index\n",
    "aminos_df = aminos_df.sort_index(axis=0)\n",
    "aminos_df = aminos_df.sort_index(axis=1)\n",
    "# Replace NaN with 0\n",
    "aminos_df.fillna(0, inplace=True)\n",
    "\n",
    "# combine the aminos_df and group_cluster_df on the index\n",
    "aminos_df = aminos_df.join(group_cluster_df)\n",
    "# divide each column by the count of the group_cluster\n",
    "for i in aminos_df.columns[:-1]:\n",
    "    aminos_df[i] = aminos_df[i]/aminos_df['count']\n",
    "# Drop the count column\n",
    "aminos_df.drop('count', axis=1, inplace=True)\n",
    "\n",
    "# Melting the dataframe for corr plotting\n",
    "acorr_df = aminos_df.copy()\n",
    "acorr_df['cluster'] = acorr_df.index\n",
    "acorr_df = acorr_df.melt(id_vars=['cluster'], var_name='aminos', value_name='Isotype Proportion')\n",
    "# Add the proportion of neural, neutral, and stem to the corr_df\n",
    "acorr_df['Neural Stem Score'] = acorr_df['cluster'].map(neural_stem_score_dict)\n",
    "# Since the mean of the neural_stem_score was taken, it needs to be scaled between -1 and 1 again\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "acorr_df['Neural Stem Score'] = scaler.fit_transform(acorr_df['Neural Stem Score'].values.reshape(-1,1))\n",
    "\n",
    "acorr_df = acorr_df.sort_values(by=['cluster','aminos'])\n",
    "# Map the dictionary to the cluster column\n",
    "acorr_df['cluster'] = acorr_df['cluster'].map(cluster_dict)\n",
    "\n",
    "# Create a diverging color palette with 64 as the separation point value meaning 1/4 of the palette is used for each side\n",
    "# cmap = sns.diverging_palette(255, 85, s=255, l=70, sep=32, as_cmap=True)\n",
    "cmap = mpl.colors.LinearSegmentedColormap.from_list('blend', ['deepskyblue','silver','gold'])\n",
    "axs = sns.relplot(x='cluster', y='aminos', hue='Neural Stem Score', size='Isotype Proportion', data=acorr_df, palette=cmap, edgecolor=\".7\", \n",
    "                  height=10, sizes=(0, 225), hue_norm=(-1, 1), size_norm=(-.01, 1))\n",
    "# Add a vertical lines to separate the clusters at the 1/4 and 3/4 range\n",
    "# axs.map(plt.axvline, x=2.5, color='black', linestyle='--')\n",
    "# axs.map(plt.axvline, x=17.5, color='black', linestyle='--')\n",
    "axs.ax.axvline(2.5, color='black', linestyle='--')\n",
    "axs.ax.axvline(17.5, color='black', linestyle='--')\n",
    "\n",
    "axs.set(ylabel=\"Isotype\", xlabel=\"Cluster Groups\", aspect=\"equal\")\n",
    "axs.despine(left=True, bottom=True)\n",
    "# Use cluster_names_dict to map the cluster number to the cluster name from earlier in the notebook\n",
    "axs.set(xticks=np.arange(len(mods_df.index)), xticklabels=[cluster_names_dict[cluster_dict_rev[i]]  for i in np.arange(0,len(mods_df.index))])\n",
    "# Set title\n",
    "plt.title('tRNA Isotype Prevalence by Cluster')\n",
    "# Move legend outside of plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., frameon=False)\n",
    "axs._legend.remove()\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/{seqtype}/cluster/amino_corr.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Plot\n",
    "\n",
    "This will generate a PCA plot that includes small RNA reads in addition to tRNA reads since the default PCA plot does not include small RNA reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "os.makedirs(f'figures/{seqtype}/pca_alt/', exist_ok=True)\n",
    "\n",
    "hue_dict = {'AlkBm_arm_d0_1': 'Day 0', 'AlkBm_arm_d0_2': 'Day 0', 'AlkBm_arm_d0_3': 'Day 0', 'AlkBm_arm_d14_1': 'Day 14', 'AlkBm_arm_d14_2': 'Day 14', 'AlkBm_arm_d35_1': 'Day 35', 'AlkBm_arm_d35_2': 'Day 35', 'AlkBm_arm_d35_3': 'Day 35', \\\n",
    "            'AlkBm_arm_d35_4': 'Day 35', 'AlkBm_arm_d35_5': 'Day 35', 'AlkBm_arm_d35_6': 'Day 35', 'AlkBm_arm_d70_1': 'Day 70', 'AlkBm_arm_d70_2': 'Day 70', 'AlkBm_arm_d70_3': 'Day 70', 'AlkBp_arm_d0_1': 'Day 0', 'AlkBp_arm_d0_2': 'Day 0', \\\n",
    "            'AlkBp_arm_d0_3': 'Day 0', 'AlkBp_arm_d0_4': 'Day 0', 'AlkBp_arm_d0_5': 'Day 0', 'AlkBp_arm_d0_6': 'Day 0', 'AlkBp_arm_d0_7': 'Day 0', 'AlkBp_arm_d0_8': 'Day 0', 'AlkBp_arm_d14_1': 'Day 14', 'AlkBp_arm_d14_2': 'Day 14', \\\n",
    "            'AlkBp_arm_d35_1': 'Day 35', 'AlkBp_arm_d35_2': 'Day 35', 'AlkBp_arm_d35_3': 'Day 35', 'AlkBp_arm_d35_4': 'Day 35', 'AlkBp_arm_d35_5': 'Day 35', 'AlkBp_arm_d70_1': 'Day 70', 'AlkBp_arm_d70_2': 'Day 70'}\n",
    "\n",
    "marker_dict = {'AlkBm_arm_d0_1': 'AlkB-', 'AlkBm_arm_d0_2': 'AlkB-', 'AlkBm_arm_d0_3': 'AlkB-', 'AlkBm_arm_d14_1': 'AlkB-', 'AlkBm_arm_d14_2': 'AlkB-', 'AlkBm_arm_d35_1': 'AlkB-', 'AlkBm_arm_d35_2': 'AlkB-', 'AlkBm_arm_d35_3': 'AlkB-',\\\n",
    "               'AlkBm_arm_d35_4': 'AlkB-', 'AlkBm_arm_d35_5': 'AlkB-', 'AlkBm_arm_d35_6': 'AlkB-', 'AlkBm_arm_d70_1': 'AlkB-', 'AlkBm_arm_d70_2': 'AlkB-', 'AlkBm_arm_d70_3': 'AlkB-', 'AlkBp_arm_d0_1': 'AlkB+', 'AlkBp_arm_d0_2': 'AlkB+', \\\n",
    "               'AlkBp_arm_d0_3': 'AlkB+', 'AlkBp_arm_d0_4': 'AlkB+', 'AlkBp_arm_d0_5': 'AlkB+', 'AlkBp_arm_d0_6': 'AlkB+', 'AlkBp_arm_d0_7': 'AlkB+', 'AlkBp_arm_d0_8': 'AlkB+', 'AlkBp_arm_d14_1': 'AlkB+', 'AlkBp_arm_d14_2': 'AlkB+', \\\n",
    "               'AlkBp_arm_d35_1': 'AlkB+', 'AlkBp_arm_d35_2': 'AlkB+', 'AlkBp_arm_d35_3': 'AlkB+', 'AlkBp_arm_d35_4': 'AlkB+', 'AlkBp_arm_d35_5': 'AlkB+', 'AlkBp_arm_d70_1': 'AlkB+', 'AlkBp_arm_d70_2': 'AlkB+'}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for i in ['nreads_fiveprime_norm','nreads_threeprime_norm','nreads_other_norm','nreads_wholecounts_norm']:\n",
    "    tdf = pd.DataFrame(adata.obs[['trna','sample',i]])\n",
    "    # add i to all in tRNA column\n",
    "    tdf['trna'] = tdf['trna'].astype(str) + '_' + i\n",
    "    # pivot the table\n",
    "    tdf = tdf.pivot(index='trna', columns='sample', values=i)\n",
    "    # Remove index/column name\n",
    "    tdf.index.name = None\n",
    "    tdf.columns.name = None\n",
    "    # Sort the columns\n",
    "    tdf = tdf.reindex(sorted(tdf.columns), axis=1)\n",
    "    # Combine the two df on matching columns\n",
    "    df = pd.concat([df, tdf], axis=0)\n",
    "\n",
    "# Sort the rows\n",
    "df = df.sort_index()\n",
    "tdf = adata.uns['nontRNA_counts'].reindex(sorted(adata.uns['nontRNA_counts'].columns), axis=1)\n",
    "df = pd.concat([df, tdf], axis=0)\n",
    "# Drop all rows with a sum less than 20\n",
    "df = df[df.sum(axis=1) >= 20]\n",
    "\n",
    "print(df)\n",
    "\n",
    "# Standardize the data\n",
    "df = pd.DataFrame(preprocessing.Normalizer().fit_transform(df), columns=df.columns, index=df.index)\n",
    "# # Create a PCA object\n",
    "pca = PCA(n_components=min(len(df.columns), 5))\n",
    "pca.fit_transform(df)\n",
    "evr = pca.explained_variance_ratio_\n",
    "\n",
    "# Transform the data and create a new dataframe\n",
    "pca_index = ['PC{}'.format(x) for x in range(1, len(evr)+1)]\n",
    "df_pca = pd.DataFrame(pca.components_, columns=df.columns, index=pca_index).T\n",
    "df_pca['hue'] = df_pca.index.map(hue_dict)\n",
    "df_pca['marker'] = df_pca.index.map(marker_dict)\n",
    "\n",
    "\n",
    "print('Principal components: {}'.format([f'PC{x}' for x in range(1, len(evr)+1)]))\n",
    "print('Explained variance: {}'.format([f'{i:.4f}' for i in pca.explained_variance_]))\n",
    "print('Explained variance ratio: {}'.format([f'{i*100:.2f}%' for i in evr]))\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = sns.barplot(x=['PC{}'.format(x) for x in range(1, len(evr)+1)], y=evr, palette=sns.hls_palette(len(evr)), hue=['PC{}'.format(x) for x in range(1, len(evr)+1)])\n",
    "# Set the x and y labels and title\n",
    "ax.set_xlabel('Principal Component')\n",
    "ax.set_ylabel('Explained Variance Ratio')\n",
    "ax.set_title('Explained Variance Ratio of Principal Components')\n",
    "# Set the box aspect ratio to 1 so the plot is square\n",
    "plt.gca().set_box_aspect(1)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "palette = {\"Day 0\": \"#007FFF\", \"Day 14\": \"#00FF7F\", \"Day 35\": \"#FF007F\", \"Day 70\": \"#FFD700\"}\n",
    "ax = sns.scatterplot(data=df_pca, x='PC1', y='PC2', s=100, palette=palette, hue='hue', style='marker')\n",
    "ax.set_xlabel('PC1 ({:.2f}%)'.format(evr[0]*100))\n",
    "ax.set_ylabel('PC2 ({:.2f}%)'.format(evr[1]*100))\n",
    "# Capatilize the legend and move the legend outside the plot and remove the border around it\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles=handles, labels=[x.capitalize() for x in labels])\n",
    "ax.legend(loc='upper left', bbox_to_anchor=(1, 1), borderaxespad=0, frameon=False)\n",
    "# ax.legend_.set_title(pcacolors.capitalize())\n",
    "# Give the plot a title\n",
    "# ax.set_title(f'PCA of {pcamarkers} colored by {pcacolors}')\n",
    "# Remove the ticks and tick labels\n",
    "ax.tick_params(axis='both', which='both', bottom=False, top=False,\n",
    "                left=False, right=False, labelbottom=False, labelleft=False)\n",
    "# Set the box aspect ratio to 1 so the plot is square\n",
    "plt.gca().set_box_aspect(1)\n",
    "plt.savefig(f'figures/{seqtype}/pca_alt/pca.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-mer Frequency Heatmap\n",
    "\n",
    "The k-mer frequency heatmap is a heatmap of the k-mer frequency in the tRNA sequences, selected by top hits from k-mer enrichment analysis in neural and stem labeled tRNAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata = ad.read_h5ad('arm.smallncRNAs.h5ad')\n",
    "rsfull_list = list(set(adata.obs['refseq'].tolist()))\n",
    "kmers_occurance_dict = {}\n",
    "kmer_freq_dict = {}\n",
    "\n",
    "def kmerGen(seq, k):\n",
    "    kmers = pd.Series([seq[x:x+k] for x in range(len(seq) - k + 1)])\n",
    "    return kmers\n",
    "\n",
    "for i in [3,4,5,6]:\n",
    "    kmer_dict = {}\n",
    "    for j in rsfull_list:\n",
    "        tkmer = kmerGen(j, i)\n",
    "        tkmer = tkmer[~tkmer.str.contains('-')] # drop kmers with gaps\n",
    "        tkmer = tkmer.value_counts().to_dict()\n",
    "        tdict = {k:kmer_dict.get(k,0)+v for k,v in tkmer.items()}\n",
    "        kmer_dict.update(tdict)\n",
    "    kmers_occurance_dict[i] = kmer_dict\n",
    "\n",
    "for i in [3,4,5,6]:\n",
    "    kmer_df = pd.DataFrame()\n",
    "    kmer_dict = {}\n",
    "    for j in rsfull_list:\n",
    "        kmer_df = pd.concat([kmer_df, pd.DataFrame(kmerGen(j, i))], axis=1)\n",
    "    for j,row in kmer_df.iterrows():\n",
    "        tdict = kmer_df.loc[j].value_counts().to_dict()\n",
    "        tdict = {k:tdict.get(k,0)/len(kmer_df.columns) for k in tdict}\n",
    "        kmer_dict[j] = tdict\n",
    "    kmer_freq_dict[i] = kmer_dict\n",
    "\n",
    "topkmersize = 10\n",
    "\n",
    "for i in [3,4,5,6]:\n",
    "    t_df = pd.DataFrame(kmers_occurance_dict[i], index=['count']).T\n",
    "    t_df = t_df.sort_values(by='count', ascending=False)\n",
    "    print(i)\n",
    "    print(t_df[0:topkmersize].index.tolist())\n",
    "    print(t_df[0:topkmersize]['count'].tolist())\n",
    "    print()\n",
    "\n",
    "# Lists taken from below\n",
    "Neural_l = ['TTCG', 'CCCC', 'GCAT', 'CCCGG', 'GGCC', 'CCGG', 'AGGC', 'TGTA', 'CCCG', 'TTCGA', 'CCC', 'GGC', 'ATG', 'GCA', 'CAC', 'GCC', 'CAT', 'GTA', 'CGA']\n",
    "Neutral_l = ['TGGC', 'CGTG', 'GGCG', 'CGTGG', 'TTCG', 'CGAA', 'GTTCG', 'CGAG', 'GGCC', 'AGGC', 'GGC', 'CGA', 'CGT', 'TCG', 'TGGC', 'GCG', 'CGC', 'CGTG']\n",
    "Stem_l = ['CCCGG', 'CCCG', 'CCGG', 'TGGT', 'ATTC', 'TCCC', 'GATTC', 'GATT', 'CGGG', 'TCCCG', 'CGG', 'TTC', 'CCG', 'GGT', 'CCC', 'ATT']\n",
    "\n",
    "# given the three lists find the difference of the three lists\n",
    "def difference(lst1, lst2, lst3): \n",
    "    return list(set(lst1) - set(lst2) - set(lst3))\n",
    "\n",
    "print(difference(Neural_l, Neutral_l, Stem_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "os.makedirs(f'figures/{seqtype}/kmer_freq/', exist_ok=True)\n",
    "\n",
    "class kmerFreqCalc():\n",
    "    def __init__(self, adata, kmer, plots, adata_grp, ccatail=True, pltshow=False, labels=None):\n",
    "        self.adata = adata\n",
    "        self.kmer = sorted(kmer)\n",
    "        self.plots = plots\n",
    "        self.adata_grp = adata_grp\n",
    "        self.ccatail = ccatail\n",
    "        self.pltshow = pltshow\n",
    "        self.labels = labels\n",
    "        self.vrange = 0.4\n",
    "        self.cmap = sns.diverging_palette(30, 170, s=255, l=70, sep=64, as_cmap=True)\n",
    "        self.total_list = self.kmerFreq(list(set(self.adata.obs['refseq'].tolist())))\n",
    "\n",
    "    def main(self):\n",
    "        # make fig and zxes with subplots equal to the number of plots\n",
    "        fig = plt.figure(figsize=(20, 3.5*len(self.plots)))\n",
    "        # Create 4 subplots with the first 3 stacked on top of each other and the last one spanning all 3 on the right\n",
    "        hr = [1]*len(self.plots)+[0.075]\n",
    "        gs = gridspec.GridSpec(len(self.plots)+1, 2, width_ratios=[1, 0.02], height_ratios=hr)\n",
    "        total_df = pd.DataFrame()\n",
    "        # Plot the heatmaps\n",
    "        for order, grp in enumerate(self.plots):\n",
    "            df = self.diffCalc(grp)\n",
    "            self.plotHeatmap(df, grp, fig, plt.subplot(gs[order,0]))\n",
    "            total_df = pd.concat([total_df, df], axis=1)\n",
    "        \n",
    "        if not self.labels:\n",
    "            # Replace all NaN with 0\n",
    "            total_df.fillna(0, inplace=True)\n",
    "            # Make a label list for the heatmaps last column\n",
    "            total_df = pd.DataFrame([total_df.max(axis=1).tolist(),total_df.min(axis=1).tolist()], index=['max','min']).T\n",
    "            total_df['diff'] = total_df['max'] - total_df['min']\n",
    "            total_df['diff'] = total_df['diff'].abs()\n",
    "            # get index of the max column greater than or equal to 0.2\n",
    "            self.labels = total_df[total_df['diff'] >= (self.vrange/2)].index.tolist()\n",
    "            self.labels = [i+1 for i in self.labels] # Correct to be 1 based\n",
    "\n",
    "        ax = plt.subplot(gs[len(self.plots)-1,0])\n",
    "        self.labels = np.linspace(1, 73, 73, dtype=int)\n",
    "        ax.set_xticks([i-0.5 for i in self.labels])\n",
    "        ax.set_xticklabels([str(i) for i in self.labels])\n",
    "\n",
    "        self.plotSchematic(plt.subplot(gs[-1, 0]))\n",
    "        ax_cb = plt.subplot(gs[0, 1])\n",
    "        # Create a legend in the right subplot for the heatmap\n",
    "        ax_cb.imshow(np.linspace(0, 100, 101).reshape(-1, 1)[::-1], cmap=self.cmap, aspect='auto', interpolation='nearest')\n",
    "        ax_cb.set_xticks([])\n",
    "        ax_cb.set_yticks([0, 25, 50, 75, 100])\n",
    "        ax_cb.set_yticklabels([f'>={self.vrange*100}%', f'{self.vrange*50}%', '0%', f'-{self.vrange*50}%', f'<=-{self.vrange*100}%'])\n",
    "        ax_cb.set_ylabel(\"Frequency from Background\", rotation=90, verticalalignment='center')  \n",
    "        ax_cb.yaxis.set_label_position(\"right\")\n",
    "        # Add title\n",
    "        fig.suptitle(f'Kmer Frequency Difference from Total for {self.kmer}')\n",
    "        # Save figure\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'figures/{seqtype}/kmer_freq/{\"_\".join([str(i) for i in self.plots])}_{\"_\".join(self.kmer)}.pdf')\n",
    "        if not self.pltshow:\n",
    "            plt.close()\n",
    "\n",
    "    def kmerGen(self, seq, ksize):\n",
    "        return pd.Series([seq[x:x+ksize] for x in range(len(seq) - ksize + 1)])\n",
    "    \n",
    "    def kmerFreq(self, klist):\n",
    "        kmer_dict = {}\n",
    "        if not self.ccatail:\n",
    "            klist = [i[0:73] for i in klist]\n",
    "        for i in list(set([len(i) for i in self.kmer])):\n",
    "            kmer_df = pd.DataFrame()\n",
    "            for j in klist:\n",
    "                kmer_df = pd.concat([kmer_df, pd.DataFrame(self.kmerGen(j, i))], axis=1)\n",
    "            for j,row in kmer_df.iterrows():\n",
    "                tdict = kmer_df.loc[j].value_counts().to_dict()\n",
    "                tdict = {k:tdict.get(k,0)/len(kmer_df.columns) for k in tdict}\n",
    "                kmer_dict[j] = kmer_dict.get(j,{})\n",
    "                kmer_dict[j].update(tdict)\n",
    "        return kmer_dict\n",
    "\n",
    "    def diffCalc(self, grp):\n",
    "        sub_list = self.adata.obs[self.adata.obs[self.adata_grp] == grp]['refseq'].tolist()\n",
    "        # if not self.ccatail:\n",
    "        #     sub_list = [i[0:73] for i in sub_list]\n",
    "        sl = self.kmerFreq(sub_list)\n",
    "        # Calc the difference between the total and the subset based on the kmer where if the number isnt in the subset it is 0\n",
    "        diff_dict = {}\n",
    "        for i in self.total_list:\n",
    "            # diff_dict[i] = {k:np.abs(sl[i].get(k,tl[i].get(k,0))-tl[i].get(k,0)) for k in tl[i]}\n",
    "            diff_dict[i] = {k:sl[i].get(k,self.total_list[i].get(k,0))-self.total_list[i].get(k,0) for k in self.total_list[i]}\n",
    "        # create a df of the enrichment of the specific kmer in the subset\n",
    "        if not self.ccatail:\n",
    "            df = pd.DataFrame(np.zeros((73,1))) # Add this column to ensure that the df is created with the correct trna length\n",
    "        else:\n",
    "            df = pd.DataFrame(np.zeros((76,1))) \n",
    "        df = pd.concat([df, pd.DataFrame(diff_dict).T], axis=1)\n",
    "        # drop the first column of zeros\n",
    "        df.drop(0, axis=1, inplace=True)\n",
    "        # Sort the columns alphabetically\n",
    "        df = df.sort_index(axis=1)\n",
    "        # Replace all NaN with 0\n",
    "        df.fillna(0, inplace=True)\n",
    "        # Print the top canidates for each group\n",
    "        # print(grp)\n",
    "        # print(df.sum(axis=0).sort_values(ascending=False)[0:10].index.tolist())\n",
    "        # if self.kmer not in df.columns then add it with all NaN\n",
    "        for i in self.kmer:\n",
    "            if i not in df.columns:\n",
    "                df[i] = np.nan\n",
    "        # drop all columns that arent the kmer\n",
    "        df = df[self.kmer]\n",
    "        # for each row conver the n last columns to NaN where n is the length of the index name\n",
    "        mask = np.zeros_like(df.T, dtype=bool)\n",
    "        for i,row in enumerate(df.T.index):\n",
    "            mask[i,-(len(row)-1):] = True\n",
    "        df = df.T.mask(mask)\n",
    "        # Sort the columns by length then alphabetically\n",
    "        df['sort_1'] = df.index.str.len()\n",
    "        df['sort_2'] = df.index\n",
    "        df = df.sort_values(by=['sort_1','sort_2'])\n",
    "        df.drop(['sort_1','sort_2'], axis=1, inplace=True)\n",
    "        df = df.T    \n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def plotHeatmap(self, df, grp, fig, ax):\n",
    "        # Create a 0.33 array as background\n",
    "        if not self.ccatail:\n",
    "            zero_df = pd.DataFrame(np.full((73, len(df.columns)), 0.33), columns=df.columns)\n",
    "        else:\n",
    "            zero_df = pd.DataFrame(np.full((76, len(df.columns)), 0.33), columns=df.columns)\n",
    "        ax = sns.heatmap(zero_df.T, cmap=\"Greys\", linewidths=.5, ax=ax, cbar=False, vmin=0, vmax=1)\n",
    "        # generate a heatmap of the df and return the ax\n",
    "        ax = sns.heatmap(df.T, cmap=self.cmap, linewidths=.5, ax=ax, cbar=False, vmin=-1*self.vrange, vmax=self.vrange)\n",
    "        # Plot dashed lines\n",
    "        for j in [7, 9, 25, 26, 43, 48, 65]:\n",
    "            ax.plot([j, j], [ax.get_ylim()[0], ax.get_ylim()[1]], color='k', linewidth=1, linestyle='--', zorder=1)\n",
    "        # Remove the x and y tick labels\n",
    "        ax.set_xticks([])\n",
    "        ax.set_xticklabels([])      \n",
    "        # Add title\n",
    "        ax.set_title(f'Cluster {grp}')\n",
    "        ax.set_xlim([0, 76])\n",
    "        if not self.ccatail:\n",
    "            ax.set_xlim([0, 73])\n",
    "        \n",
    "    def plotSchematic(self, ax):\n",
    "        # Create the tRNA scheme in the bottom subplot\n",
    "        ax.set_ylim([-1, 1])\n",
    "        ax.set_xlim([0, 76])\n",
    "        if not self.ccatail:\n",
    "            ax.set_xlim([0, 73])\n",
    "        ax.axhspan(-0.125, 0.125, color='black', zorder=-3)\n",
    "        # Plot the tRNA scheme\n",
    "        ax.axvspan(9, 25, color='#ff9999', zorder=-2) # D-Arm/Loop Outer\n",
    "        ax.axvspan(13, 21, color='white', alpha=0.8, zorder=-1) # D-Arm/Loop Inner\n",
    "        ax.axvspan(26, 43, color='#99ff99', zorder=-2) # A-Arm/Loop Outter\n",
    "        ax.axvspan(31, 38, color='white', alpha=0.8, zorder=-1) # A-Arm/Loop Inner\n",
    "        ax.axvspan(48, 65, color='#99ffff', zorder=-2) # T-Arm/Loop Outter\n",
    "        ax.axvspan(53, 60, color='white', alpha=0.8, zorder=-1) # T-Arm/Loop Inner\n",
    "        ax.axvspan(0, 7, color='#98c0c0', zorder=-2) # Stem 1\n",
    "        if not self.ccatail:\n",
    "            ax.axvspan(65, 73, color='#98c0c0', zorder=-2)\n",
    "        else:\n",
    "            ax.axvspan(65, 76, color='#98c0c0', zorder=-2) # Stem 2\n",
    "        # # Plot the tRNA scheme text\n",
    "        ax.text(17, 0, 'D-Arm/Loop', fontsize=10, verticalalignment='center', horizontalalignment='center', color='k')\n",
    "        ax.text(35, 0, 'A-Arm/Loop', fontsize=10, verticalalignment='center', horizontalalignment='center', color='k')\n",
    "        ax.text(56, 0, 'T-Arm/Loop', fontsize=10, verticalalignment='center', horizontalalignment='center', color='k')\n",
    "        # Plot dashed lines\n",
    "        for j in [7, 9, 25, 26, 43, 48, 65]:\n",
    "            ax.plot([j, j], [ax.get_ylim()[0], ax.get_ylim()[1]], color='k', linewidth=1, linestyle='--', zorder=1)\n",
    "        # Remove the axis spines for ax3\n",
    "        ax.axis('off')\n",
    "\n",
    "label_list = None\n",
    "kmer_list =  ['CCCC', 'GGGG', 'TGTA', 'CAC', 'ATG', 'GTA', 'GCC', 'GCAT']  \n",
    "\n",
    "adata_grp = 'group_cluster_neural'\n",
    "plot = sorted(adata.obs[adata_grp].unique().tolist())\n",
    "# remove the 'Too Low' and 'Undetermined' from the plot list\n",
    "plot.remove('Too Low')\n",
    "# plot.remove('Undetermined')\n",
    "kmerFreqCalc(adata, kmer_list, plot, adata_grp, pltshow=True, ccatail=False, labels=label_list).main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small RNA-seq Barplots\n",
    "\n",
    "These plots require `statannotations` in order to run however at this time the dependencies for that require `Seaborn<=0.12` which causes issues with other plots in this pipeline. These plots should be generated manually but the code is provided for reference.\n",
    "\n",
    "```Python\n",
    "from statannotations.Annotator import Annotator\n",
    "\n",
    "def rna_barplot(df, readtype, seqtype):\n",
    "    # Subset the df\n",
    "    df = df[df['readtype'] == readtype]\n",
    "    # Define Pallete\n",
    "    pal = {'d0':'#007FFF','d14':'#00FF7F','d35':'#FF007F','d70':'#FFD700'}\n",
    "    test_type = 't-test_welch'\n",
    "    # Creat fig\n",
    "    fig, axs = plt.subplots(figsize=(6,5))\n",
    "    sns.barplot(data=df, x='treatment', y='count', hue='timepoint', palette=pal, ax=axs)\n",
    "    # Add statistical annotation\n",
    "    annotator = Annotator(axs, pairs=[('AlkBp','AlkBm')], data=df, x='treatment', y='count', order=['AlkBp','AlkBm'])\n",
    "    annotator.configure(test=test_type, text_format='star', loc='inside', verbose=0)\n",
    "    annotator.apply_and_annotate()\n",
    "    # Y axis label\n",
    "    axs.set_ylabel('Normalized Reads')\n",
    "    # X axis label\n",
    "    axs.set_xlabel('')\n",
    "    # Add title\n",
    "    plt.title(f'{readtype} Reads')\n",
    "    # Move legend outside of plot\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), title='Timepoint', frameon=False)\n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/{seqtype}/bar/treatment_{readtype}_compare_{test_type}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    # Creat fig\n",
    "    fig, axs = plt.subplots(figsize=(6,5))\n",
    "    sns.barplot(data=df, x='group', y='count', hue='timepoint', palette=pal, ax=axs)\n",
    "    # Add statistical annotation\n",
    "    ppairs = [('d0_AlkBm','d14_AlkBm'),('d0_AlkBm','d35_AlkBm'),('d0_AlkBm','d70_AlkBm'),('d0_AlkBp','d14_AlkBp'),('d0_AlkBp','d35_AlkBp'),('d0_AlkBp','d70_AlkBp')]\n",
    "    oorder = ['d0_AlkBm','d14_AlkBm','d35_AlkBm','d70_AlkBm','d0_AlkBp','d14_AlkBp','d35_AlkBp','d70_AlkBp']\n",
    "    annotator = Annotator(axs, pairs=ppairs, data=df, x='group', y='count', order=oorder)\n",
    "    annotator.configure(test=test_type, text_format='star', loc='inside', verbose=0)\n",
    "    annotator.apply_and_annotate()\n",
    "    # Y axis label\n",
    "    axs.set_ylabel('Normalized Reads')\n",
    "    # X axis label\n",
    "    axs.set_xlabel('')\n",
    "    # Remove xticks and only have the two for the groups\n",
    "    if seqtype == 'arm.smallncRNAs':\n",
    "        axs.set_xticks([1.5,5.5])\n",
    "    else:\n",
    "        axs.set_xticks([0.5,2.5])\n",
    "    axs.set_xticklabels(['AlkBm','AlkBp'])\n",
    "    # Add title\n",
    "    plt.title(f'{readtype} Reads')\n",
    "    # Move legend outside of plot\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), title='Timepoint', frameon=False)\n",
    "    # Save figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'figures/{seqtype}/bar/timepoint_{readtype}_compare_{test_type}.pdf')\n",
    "    plt.close()\n",
    "\n",
    "for seqtype in seqtypes:\n",
    "    os.makedirs(f'figures/{seqtype}/bar', exist_ok=True)\n",
    "    adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "    df = adata.uns['type_real_counts'].T\n",
    "    # Get readtypes for plots\n",
    "    readtypes = sorted(df.columns)\n",
    "    # Split the names into group and timepoint\n",
    "    df['treatment'] = [i.split('_')[0] for i in df.index]\n",
    "    df['timepoint'] = [i.split('_')[2] for i in df.index]\n",
    "    df['sample'] = df.index\n",
    "    df['group'] = df['timepoint'] + '_' + df['treatment']\n",
    "    # Melt the df for bar plots\n",
    "    df = pd.melt(df, id_vars=['treatment','timepoint','sample','group'], value_vars=readtypes, var_name='readtype', value_name='count')\n",
    "\n",
    "    for rt in readtypes:\n",
    "        rna_barplot(df, rt, seqtype)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Bulk visualizations\n",
    "\n",
    "The following code will run the graphing part of the pipeline with the following configuration to subset the data into pAlkB samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate all the main plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqtype in seqtypes:\n",
    "    for config in ['','--config config/AlkBp.json']:\n",
    "        print(f'Generating figures for {seqtype} with {config}...')\n",
    "        !../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad {config} --colormap config/colormap.json -g correlation count heatmap pca radar volcano -o figures/{seqtype}/ \\\n",
    "          --heatgrp timepoint --heatsubplots --heatcutoff 55 --heatbound 15 --bargrp timepoint --covgrp timepoint --radargrp timepoint --radarscaled --radarmethod all --corrgroup group --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate specific bar plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "# Create standard bar plots\n",
    "print(f'Generating standard bar plots for {seqtype}...')\n",
    "for i in [('amino','timepoint'),('iso','timepoint')]:\n",
    "    !../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g bar --bargrp {i[0]} --barcol {i[1]} -o figures/{seqtype}/ --quiet\n",
    "# Create sub bar plots\n",
    "print(f'Generating sub bar plots for {seqtype}...')\n",
    "for i in [('iso','amino','timepoint'),('trna','iso','timepoint')]:\n",
    "    ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g bar --bargrp {i[0]} --barsubgrp {i[1]} --barcol {i[2]} -o figures/{seqtype}/ --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sorted by neural category bar plots for ARMseq\n",
    "print('Generating sorted by neural and epi category bar plots for ARMseq...')\n",
    "for i in [('neural_broad','group_cluster'),('treatment','group_cluster'),('timepoint','group_cluster')]:\n",
    "    ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g bar --bargrp {i[0]} --barcol {i[1]} --barsort 'group_cluster_score' --barlabel 'group_cluster_fancy' -o figures/{seqtype}/ #--quiet\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate specific combined coverage plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "for cg,co in [('timepoint','iso'), ('timepoint','trna')]:\n",
    "    print(f'Generating combined coverage figures for ARMseq for {cg} by {co}...')\n",
    "    # ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --config config/AlkBp.json --colormap config/colormap.json -g coverage --covgrp {cg} --covobs {co} --covmethod mean -o figures/{seqtype}/ --covtype mismatchedbases --quiet\n",
    "    # ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --config config/AlkBp.json --colormap config/colormap.json -g coverage --covgrp {cg} --covobs {co} --covmethod mean -o figures/{seqtype}/ --covtype readstarts --quiet\n",
    "    ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --config config/AlkBp.json --colormap config/colormap.json -g coverage --covgrp {cg} --covobs {co} --covmethod mean -o figures/{seqtype}/ --covtype uniquecoverage --quiet\n",
    "    # ! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --config config/AlkBp.json --colormap config/colormap.json -g coverage --covgrp {cg} --covobs {co} --covmethod sum -o figures/{seqtype}/ --covtype uniquecoverage --quiet\n",
    "\n",
    "print('Generating coverage figures for ARMseq for group_cluster...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g coverage --covgrp group_cluster_fancy --covobs group_cluster_fancy --covmethod mean -o figures/{seqtype}/ --quiet\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate specific seqLogos and seqmaps for ARMseq data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqtype = 'arm.smallncRNAs'\n",
    "\n",
    "adata = ad.read_h5ad(f'{seqtype}.h5ad')\n",
    "# Generate logo plots for ARMseq based on group_cluster\n",
    "print('Generating logo plots for ARMseq based on group_cluster...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logogrp group_cluster -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "\n",
    "neural_clusters = [7,18,19,12,1]\n",
    "stem_clusters = [6,2,10,8,9,3]\n",
    "\n",
    "print('Generating logo plots for ARMseq based on tRNA-Arg-TCT-1 and tRNA-Arg-TCT-4...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp tRNA-Arg-TCT-1 tRNA-Arg-TCT-2 tRNA-Arg-TCT-3 tRNA-Arg-TCT-4 tRNA-Arg-TCT-5 --logomanualname Arg-TCT -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp tRNA-Arg-TCT-1 tRNA-Arg-TCT-4 --logomanualname Arg-TCT-1_4 -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp tRNA-Arg-TCT-4 --logomanualname Arg-TCT-4 -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "\n",
    "tlist = []\n",
    "for i in neural_clusters:\n",
    "    tlist.append(adata.obs[adata.obs['group_cluster'].isin(neural_clusters)]['trna'].unique().tolist())\n",
    "tlist = sorted(set(tlist[0]))\n",
    "tlist = ' '.join(tlist)\n",
    "tname = 'neural_clusters'\n",
    "    \n",
    "print('Generating logo plots for ARMseq based on neural_clusters...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json --config config/AlkBp.json -g logo --logomanualgrp {tlist} --logomanualname {tname} -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "\n",
    "tlist = []\n",
    "for i in stem_clusters:\n",
    "    tlist.append(adata.obs[adata.obs['group_cluster'].isin(stem_clusters)]['trna'].unique().tolist())\n",
    "tlist = sorted(set(tlist[0]))\n",
    "tlist = ' '.join(tlist)\n",
    "tname = 'stem_clusters'\n",
    "\n",
    "print('Generating logo plots for ARMseq based on stem_clusters...')\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp {tlist} --logomanualname {tname} -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "\n",
    "# Based on the top 15 neural expression from differential expression (Fig 2)\n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp tRNA-SeC-TCA-1 tRNA-Arg-TCT-4 tRNA-Ala-AGC-8 tRNA-Gly-CCC-2 tRNA-Leu-AAG-5 \\\n",
    "    tRNA-Leu-TAG-3 tRNA-Gly-GCC-2 tRNA-Arg-CCT-4 tRNA-Leu-AAG-2 tRNA-Ser-TGA-1 tRNA-Arg-CCT-2 tRNA-Ala-AGC-4 tRNA-Ser-GCT-3 tRNA-Ala-TGC-3 tRNA-Ala-TGC-4 \\\n",
    "    --logomanualname neural_top_15 -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp tRNA-SeC-TCA-1 tRNA-Arg-TCT-4 tRNA-Ala-AGC-8 tRNA-Gly-CCC-2 tRNA-Leu-AAG-5 \\\n",
    "    tRNA-Leu-TAG-3 tRNA-Gly-GCC-2 tRNA-Arg-CCT-4 tRNA-Leu-AAG-2 tRNA-Ser-TGA-1 tRNA-Arg-CCT-2 tRNA-Ala-AGC-4 tRNA-Ser-GCT-3 \\\n",
    "    --logomanualname neural_top_15_13_subset -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet \n",
    "! ../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad --colormap config/colormap.json -g logo --logomanualgrp tRNA-Ala-TGC-3 tRNA-Ala-TGC-4 \\\n",
    "    --logomanualname neural_top_15_2_subset -o figures/{seqtype}/ --logosize sprinzl --ccatail --logornamode --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqtype in seqtypes:\n",
    "    for config in ['--config config/AlkBp.json']:\n",
    "        print(f'Generating figures for {seqtype} with {config}...')\n",
    "        !../tRNAgraph/trnagraph.py graph -i {seqtype}.h5ad {config} --colormap config/colormap.json -g radar -o figures/{seqtype}/ --radargrp timepoint --radarscaled --radarmethod mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Supplemental data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerebral organoid expression from RNAseq data is used and correlated. `1-s2.0-S0092867418303830-mmc2.csv` supplementary data from [https://doi.org/10.1016/j.cell.2018.03.051](https://doi.org/10.1016/j.cell.2018.03.051) was loaded and used to plot the expression of tRNA modification enzymes in the RNAseq data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('supplemental/1-s2.0-S0092867418303830-mmc2.csv')\n",
    "\n",
    "# Add mean reads across all timepoints\n",
    "df['mean_reads'] = df[['baseMean_hESw0','baseMean_hESw1','baseMean_hESw2','baseMean_hESw3','baseMean_hESw4','baseMean_hESw5']].mean(axis=1)\n",
    "\n",
    "# Add log2diff between the 0 and 5 timepoints\n",
    "df['log2diff'] = np.log2(df['baseMean_hESw5'] + 1) - np.log2(df['baseMean_hESw0'] + 1)\n",
    "\n",
    "x = np.array([i for i in range(6)])\n",
    "y = df[['baseMean_hESw0','baseMean_hESw1','baseMean_hESw2','baseMean_hESw3','baseMean_hESw4','baseMean_hESw5']].values\n",
    "slopes, intercepts = [],[]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    slope, intercept = np.polyfit(x, y[i], 1)\n",
    "    slopes.append(slope)\n",
    "    intercepts.append(intercept)\n",
    "\n",
    "df['slope'] = slopes\n",
    "df['intercept'] = intercepts\n",
    "# Normalize the slope between -1 and 1\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
    "df['slope_scaled'] = scaler.fit_transform(df['slope'].values.reshape(-1,1))\n",
    "# Sort the df by the slope_scaled\n",
    "df = df.sort_values(by='slope_scaled', ascending=False)\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tRNA modification and disease data was obtained from from de [Crécy-Lagard et al. 2019](https://pmc.ncbi.nlm.nih.gov/articles/PMC6412123/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_disease = pd.read_csv('supplemental/mods_disease.tsv', sep='\\t')\n",
    "# Fill NaN with False\n",
    "df_disease.fillna(False, inplace=True)\n",
    "# Drop Non tRNA causes\n",
    "df_disease = df_disease[df_disease['Non tRNA cause'] == False]\n",
    "diseses_list = ['microcephaly','developmental delay','intellectual disabilities','developmental defects','cmt','als','autism spectrum disorder','molybdenum cofactor deficiency','friedreich ataxia','galloway-mowat syndrome','neurodegeneration','encephalopathy','leigh syndrome','epilepsy',]\n",
    "disease_genes = []\n",
    "for i in diseses_list:\n",
    "    disease_genes += df_disease[df_disease[i] == True]['Gene'].tolist()\n",
    "disease_genes = list(set(disease_genes))\n",
    "df_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame()\n",
    "\n",
    "# print(disease_genes)\n",
    "# Disease list\n",
    "target_genes = ['HSD17B10','PUS10','OSGEP','LAGE3','TRMT1','PUS3','ADAT3','FTSJ1','ELP4','TPRKB','TRMT10A','TRIT1', 'THG1L']\n",
    "# Position list\n",
    "target_genes += ['ADAT1','ADAT3','DTWD1','DTWD2','NSUN2','PUS1','PUS3','TRMT1','TRMT61A','TRMT10A','METTL6']\n",
    "print(target_genes)\n",
    "\n",
    "for i in list(set(target_genes)):\n",
    "    df_sub = pd.concat([df_sub, df[df['gene_symbol']==i]])\n",
    "\n",
    "# target_genes = ['NSUN','PUS3','PUS1','TRMT1','ADAT3','TRMT6','ACP3U','DTWD1','DTWD2','TRMT5','TRMT61A','ADAT1']\n",
    "# for i in list(set(disease_genes + target_genes)):\n",
    "#     df_sub = pd.concat([df_sub, df[df['gene_symbol']==i]])\n",
    "\n",
    "df_sub = df_sub[['gene_symbol','baseMean_hESw0','baseMean_hESw1','baseMean_hESw2','baseMean_hESw3','baseMean_hESw4','baseMean_hESw5']]\n",
    "df_sub = df_sub.set_index('gene_symbol')\n",
    "\n",
    "\n",
    "df_sub = pd.DataFrame(preprocessing.Normalizer(norm='l2').fit_transform(df_sub),columns=df_sub.columns,index=df_sub.index)\n",
    "\n",
    "# Sort the df by baseMean_hESw0 then baseMean_hESw5\n",
    "df_sub['diff'] = df_sub['baseMean_hESw5'] - df_sub['baseMean_hESw0']\n",
    "df_sub = df_sub.sort_values(by='diff', ascending=False)\n",
    "df_sub.drop('diff', axis=1, inplace=True)\n",
    "# Sort by gene_sumbol\n",
    "# df_sub = df_sub.sort_index()\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(12,5))\n",
    "sns.heatmap(df_sub[['baseMean_hESw0','baseMean_hESw1','baseMean_hESw2','baseMean_hESw3','baseMean_hESw4','baseMean_hESw5']].T, annot=False, cmap='mako_r',  ax=axs)\n",
    "# Remove the yticklabels\n",
    "axs.set_yticklabels(['Week 0','Week 1','Week 2','Week 3','Week 4','Week 5'], rotation=0)\n",
    "axs.set_ylabel('Timepoint')\n",
    "# Add title\n",
    "plt.title('tRNA Expression in hESCs')\n",
    "# Save figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'figures/hESC_tRNA_expression.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. CSV exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seqtype in ['arm.smallncRNAs']:\n",
    "    !../tRNAgraph/trnagraph.py tools csv -i {seqtype}.h5ad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
